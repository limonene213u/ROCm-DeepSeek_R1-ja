# 研究手順

## ⚠️ 重要な運用指針

**このファイルは本プロジェクトの唯一の研究・実験手順書です。**

## 環境要件

ROCmが必要なのはGPUベンチマーク実行時のみ。統計解析やデータ前処理はCPU環境で実行可能。

## 1. 初期環境セットアップ（必須）

### 1.1 環境構築

```bash
# 基本環境セットアップ
cd setup/
python setup.py

# 依存関係インストール
bash pip_install.sh
```

**目的**: ROCm/CUDA環境の自動判別、PyTorchとHuggingFaceライブラリの最適インストール

**成果物**: 最適化された深層学習環境

**評価**: セットアップエラーなく完了、GPUが正しく認識されることを確認

## 2. データセット準備（並行実行可能）

### 2.1 基本データセット収集

```bash
python Python/dl_dataset.py
```

**目的**: CC-100日本語コーパス、Wikipedia日本語データの自動収集と前処理

**成果物**: `Python/dataset/deepseek-jp/` 配下に構造化されたデータセット

**評価**: データ品質チェック、文字エンコーディング検証、サイズ確認

### 2.2 データセット品質向上（オプション）

```bash
python Python/dataset_quality_enhancer.py
```

**目的**: ノイズ除去、重複排除、言語判定による品質向上

**成果物**: 高品質化されたトレーニングデータ

**評価**: ノイズ除去率、データサイズ変化率の測定

### 2.3 不足データ補完（オプション）

```bash
python Python/missing_dataset_generator.py
```

**目的**: 特定ドメインのデータ不足を補完する合成データ生成

**成果物**: 補完的トレーニングデータ

**評価**: 生成データの品質評価、多様性スコア測定

## 3. モデル分析・選定（重要）

### 3.1 DeepSeek R1モデル分析

```bash
# 軽量版（推奨）
python Python/Analyze_DeepSeekR1/analyze_deepseekr1_lite.py

# フル機能版（可視化付き）
python Python/Analyze_DeepSeekR1/analyze_deepseekr1.py
```

**目的**:

- DeepSeek R1 Distillシリーズの日本語トークナイザー性能分析
- BPE語彙の日本語カバレッジ評価
- モデルサイズ別の特性比較

**成果物**: `Analyze_DeepSeekR1_Data/` 配下に詳細分析レポート

**評価**:

- 日本語トークン比率
- 文字体系別分布（ひらがな/カタカナ/漢字）
- サブワード分割効率性
- 一般的日本語単語のカバレッジ

### 3.2 モデル選定指針

| モデル | メモリ | 推奨用途 | 実行コマンド |
|--------|--------|----------|--------------|
| **Qwen-1.5B** | 4GB | 実験・テスト | `--model-type qwen-1.5b` |
| **Llama-8B** | 16GB | 高速推論・軽量環境 | `--model-type llama-8b` |
| **Qwen-14B** | 28GB | バランス型（推奨） | `--model-type qwen-14b` |
| **Qwen-32B** | 64GB | 高性能・研究用途 | `--model-type qwen-32b` |

## 4. 日本語特化学習

### 4.1 試行モード（初回推奨）

```bash
python Python/deepseek_ja_adapter.py --mode trial --auto
```

**目的**: 最小サンプル（50件）での動作確認とパラメータ調整

**成果物**: 学習パイプラインの動作確認

**評価**: エラーなく完了、メモリ使用量、学習時間の測定

### 4.2 開発モード（パラメータ調整）

```bash
python Python/deepseek_ja_adapter.py --mode development --epochs 3
```

**目的**: サンプル200件での実験、ハイパーパラメータ最適化

**成果物**: 調整された学習設定

**評価**: 学習曲線、損失関数の収束確認

### 4.3 本格学習（実運用）

```bash
# バランス型（推奨）
python Python/deepseek_ja_adapter.py --model-type qwen-14b --mode production --epochs 10

# 高性能版
python Python/deepseek_ja_adapter.py --model-type qwen-32b --mode production --epochs 10
```

**目的**: 実データセットでの本格的日本語特化学習

**成果物**: 日本語特化DeepSeek R1モデル

**評価**:

- 学習損失の推移
- 日本語生成品質
- Perplexity値の改善

## 5. 性能ベンチマーク（重要）

### 5.1 LoRA効率性ベンチマーク

```bash
python Python/lora_efficiency_benchmark.py
```

**目的**: LoRAパラメータ設定の最適化とメモリ効率性評価

**成果物**: LoRA設定別性能比較レポート

**評価**:

- メモリ使用効率
- 学習速度
- 精度維持率

### 5.2 MLA KVキャッシュベンチマーク（GPU必須）

```bash
python Python/mla_kv_cache_benchmark.py
```

**目的**: Multi-Head Latent Attentionの日本語処理におけるKVキャッシュ効率評価

**成果物**: MLA最適化パラメータ

**評価**:

- メモリ使用量削減率
- 推論速度向上率
- 精度維持度

## 6. 統計解析・検証

### 6.1 R統計解析

```bash
cd R/Analyze_DeepSeekR1/
Rscript deepseek_r1_statistical_analysis.R
```

**目的**: 学習結果の統計的有意性検証、論文向け統計解析

**成果物**: 統計分析レポート、可視化グラフ

**評価**:

- 統計的有意性（p値）
- 効果量（Cohen's d）
- 信頼区間

### 6.2 論文検証スイート

```bash
python Python/paper_validation_suite.py
```

**目的**: 研究成果の再現性確保、論文主張の客観的検証

**成果物**: 検証レポート

**評価**: 全検証項目のpass/fail状況

### 6.3 検証実行ランナー

```bash
python Python/paper_validation_runner.py
```

**目的**: 自動化された検証パイプラインの実行

**成果物**: 統合検証レポート

**評価**: 総合品質スコア

## 7. 実行順序とワークフロー

### フェーズ1: 準備（並行実行可能）

1. **環境セットアップ** （setup/setup.py）
2. **データセット収集** （Python/dl_dataset.py）
3. **モデル分析** （Python/Analyze_DeepSeekR1/）

### フェーズ2: 学習と最適化

1. **試行モード** → **開発モード** → **本格学習**
2. **ベンチマーク実行** （効率性評価）

### フェーズ3: 検証と解析

1. **統計解析** （R/Analyze_DeepSeekR1/）
2. **論文検証** （Python/paper_validation_suite.py）

## 8. 品質評価指標

### 学習品質

- **Perplexity**: 日本語テキストでの混乱度（低いほど良い）
- **BLEU Score**: 日本語生成品質（高いほど良い）
- **学習曲線**: 損失関数の収束性

### 効率性指標

- **メモリ効率**: ピークメモリ使用量
- **学習速度**: エポック当たりの時間
- **推論速度**: トークン/秒

### 日本語対応指標

- **語彙カバレッジ**: 日本語トークン比率
- **文字体系バランス**: ひらがな/カタカナ/漢字の分布
- **サブワード効率**: 平均分割数

## 9. トラブルシューティング

### GPU関連

```bash
# ROCm環境確認
rocm-smi

# CUDA環境確認
nvidia-smi
```

### メモリ不足対応

- モデルサイズ変更: `--model-type qwen-1.5b`
- バッチサイズ調整: `--batch-size 1`
- 勾配蓄積: `--gradient-accumulation-steps 4`

### データセット問題

```bash
# データセット再生成
python Python/missing_dataset_generator.py --force-regenerate
```

## 10. 継続学習・改良

### 既存モデルからの継続

```bash
python Python/deepseek_ja_adapter.py --continue-from ./output/previous_model --epochs 5
```

### パラメータ最適化

```bash
# 設定確認（ドライラン）
python Python/deepseek_ja_adapter.py --model-type qwen-14b --dry-run
```

この手順に従うことで、DeepSeek R1の日本語特化学習から論文品質の検証まで、再現性の高い研究プロセスを実行できます。
